# -*- coding: utf-8 -*-
"""power_consumption_exploration.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hDPyE7zsm65ttCcZ8G-uR8om_h350y4d
"""

# Household Power Consumption Forecasting
import pandas as pd
import numpy as np
from  sklearn.preprocessing import RobustScaler, OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.metrics import mean_squared_error


# UCI ML Repository, Sceaux, France which contains 4 years of minute-level measurements of power consumption for a household in Sceaux, France.
#  link https://archive.ics.uci.edu/dataset/235/individual+household+electric+power+consumption


df = pd.read_csv('household_power_consumption.txt', sep=';', low_memory=False)
print(df.head()) # Global_active_power -> target
print(df.info())
print(df.describe())

"""Numeric Columns given as Object Handle it"""

# df['Sub_metering_3'].value_counts() -> all columns except Date and Time are numbers given as object

num_cols = ['Global_active_power','Global_reactive_power','Voltage',
            'Global_intensity','Sub_metering_1','Sub_metering_2','Sub_metering_3']

for col in num_cols:
    df[col] = df[col].replace([' ','?'], np.nan).astype(float)

df.info()

"""Creating Lag Features"""

# Create lag features
df['lag_1'] = df['Global_active_power'].shift(1)  # 1 step back
df['lag_2'] = df['Global_active_power'].shift(2)  # 2 steps back
df = df.dropna(subset=['lag_1', 'lag_2']) # dropping rather than using ffill and bfill to get false information

"""Adding Datetime feature"""

df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%d/%m/%Y %H:%M:%S')
df = df.sort_values('Datetime').reset_index(drop=True)
df.head()

df.head()

"""Time Based Split"""

import pandas as pd


x = df.drop(columns=['Global_active_power', 'Date', 'Time']) # we have combined Datetime so dont need date time separately
#combining Datetime help us with extracting[hours , weeks, ...] , Sorting, Splitting easier & less complicated.
y = df['Global_active_power']   # target

# splitting the data by Datetime
split_date = '2010-01-01'

x_train = x[x['Datetime'] < split_date]
x_test  = x[x['Datetime'] >= split_date]

y_train = y[df['Datetime'] < split_date]
y_test  = y[df['Datetime'] >= split_date]

# splitting the data into 80% train & 20% test -> not good mix future and past data which allows model to learn from future data leading to overly optimistic result
# split_idx = int(len(df) * 0.8)

# x_train = x.iloc[:split_idx]
# x_test  = x.iloc[split_idx:]

# y_train = y.iloc[:split_idx]
# y_test  = y.iloc[split_idx:]

x_train.head()

y_train.head()

"""Checking and Handling the missing values"""

x_train.isna().sum()

x_train.head()

x_test.head()

from sklearn.impute import SimpleImputer

num_cols = ['Global_reactive_power','Voltage',
            'Global_intensity','Sub_metering_1','Sub_metering_2','Sub_metering_3']

imputer = SimpleImputer(strategy='mean')
x_train[num_cols] = imputer.fit_transform(x_train[num_cols])
x_test[num_cols] = imputer.transform(x_test[num_cols])
print(x_train.isna().sum())

x_train.isna().sum()

y_train.isna().sum()

# dropping NaN from train and test data
x_train, y_train = x_train[y_train.notna()], y_train[y_train.notna()]
x_test, y_test = x_test[y_test.notna()], y_test[y_test.notna()]

"""Checking and handling the outlier"""

outliers_dict = {}
for col in x_train.select_dtypes(include=['float64', 'int64']).columns:
    Q1 = x_train[col].quantile(0.25)
    Q3 = x_train[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outlier_rows = x_train[(x_train[col] < lower_bound) | (x_train[col] > upper_bound)][col]
    outliers_dict[col] = outlier_rows

    print(f"{col}: {len(outlier_rows)} outliers")


#dtected outliers via IQR but kept them because power data has natural spikes
print("\nOutliers per column:")
for col, outliers in outliers_dict.items():
    print(f"{col}: {outliers.values}")

"""checking and handling skewness"""

numeric_cols = x_train.select_dtypes(include=['float64', 'int64']).columns #'DatetimeArray' with dtype datetime64[ns] does not support reduction 'skew'
skewness = x_train[numeric_cols].skew()
print(skewness.sort_values(ascending=False))
transform_cols = skewness[skewness > 2].index

transform_cols

from sklearn.preprocessing import PowerTransformer
pt = PowerTransformer()#default is yeo-johnson
x_train.loc[:, transform_cols]  = pt.fit_transform(x_train[transform_cols])
x_test.loc[:, transform_cols] = pt.transform(x_test[transform_cols])

"""Checking variance & correlation"""

x_train[num_cols].var()

x_train.corr()

x_train.corrwith(y_train) # checking correlation of features with target

x_train['hour'] = x_train['Datetime'].dt.hour
x_train['day_of_week'] = x_train['Datetime'].dt.dayofweek
x_train['month'] = x_train['Datetime'].dt.month

x_test['hour'] = x_test['Datetime'].dt.hour
x_test['day_of_week'] = x_test['Datetime'].dt.dayofweek
x_test['month'] = x_test['Datetime'].dt.month

x_train = x_train.drop(columns=['Datetime'])
x_test = x_test.drop(columns=['Datetime'])

from sklearn.feature_selection import mutual_info_regression
mutual_info = mutual_info_regression
sample_size = 100_000
sample_idx = x_train.sample(n=sample_size, random_state=42).index
test_sample_size = 20_000

x_train_sample = x_train.sample(n=sample_size, random_state=42)
y_train_sample = y_train.loc[x_train_sample.index]

x_test_sample = x_test.sample(n=test_sample_size, random_state=42)
y_test_sample = y_test.loc[x_test_sample.index]

mi_scores = mutual_info_regression(x_train_sample, y_train_sample)

mi_scores = pd.Series(mi_scores, name="MI Scores", index=x_train_sample.columns)
mi_scores = mi_scores.sort_values(ascending=False)
print(mi_scores)

x_test.isna().sum()

print(y_test.isna().sum())

x_test_sample.head()

x_train_sample.head()

y_train_sample

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
#models dont take Datetime type
models = {
    'Linear Regression': LinearRegression(),
    'Random Forest': RandomForestRegressor(n_estimators=50, max_depth=10, n_jobs=-1)
}
results = {}
for name,model in models.items():
    model.fit(x_train_sample, y_train_sample)
    y_pred = model.predict(x_test_sample)
    results[name] = {
        "Mean Square Error(MSE)":mean_squared_error(y_test_sample, y_pred),
        "Root Mean Squared Error (RMSE)": np.sqrt(mean_squared_error(y_test_sample, y_pred)),
        "Mean Absolute Error (MAE)" : mean_absolute_error(y_test_sample, y_pred),
        "R² Score (Coefficient of Determination)":r2_score(y_test_sample, y_pred)
        }

(results)
# MSE, RMSE, MAE: smaller → better. Zero is perfect.

# R²: closer to 1 → better. Negative → model is bad.
# {'Linear Regression': {'Mean Square Error(MSE)': 0.0014928603441541196,
#   'Root Mean Squared Error (RMSE)': np.float64(0.03863755095957972),
#   'Mean Absolute Error (MAE)': 0.02440409811272028,
#   'R² Score (Coefficient of Determination)': 0.9983136307610663},
#  'Random Forest': {'Mean Square Error(MSE)': 0.0010555048181503089,
#   'Root Mean Squared Error (RMSE)': np.float64(0.03248853364112189),
#   'Mean Absolute Error (MAE)': 0.017403584654765256,
#   'R² Score (Coefficient of Determination)': 0.9988076775809304}}

"""Groupwise Average Power prediction"""

x_test_copy = x_test_sample.copy()
x_test_copy['Predicted_Power'] = y_pred

x_test_copy['Voltage_bin'] = pd.cut(x_test_copy['Voltage'], bins=10)
print(x_test_copy.groupby('Voltage_bin', observed=True)['Predicted_Power'].mean())
x_test_copy['Global_intensity'] = pd.cut(x_test_copy['Global_intensity'], bins=10)
print(x_test_copy.groupby('Global_intensity', observed=True)['Predicted_Power'].mean())
x_test_copy['Global_reactive_power'] = pd.cut(x_test_copy['Global_reactive_power'], bins=10)
print(x_test_copy.groupby('Global_reactive_power', observed=True)['Predicted_Power'].mean())
x_test_copy['Sub_metering_1'] = pd.cut(x_test_copy['Sub_metering_1'], bins=10)
print(x_test_copy.groupby('Sub_metering_1', observed=True)['Predicted_Power'].mean())

from sklearn.model_selection import RandomizedSearchCV
x_train_small = x_train_sample.sample(n=20000, random_state=42)
y_train_small = y_train_sample.loc[x_train_small.index]
param_dist = {
    'n_estimators': [10, 20],  # very small numbers for hyperparameter search
    'max_depth': [6, 8, 10],
    'min_samples_leaf': [1, 2, 4],
}

rs = RandomizedSearchCV(
    RandomForestRegressor(),
    param_distributions=param_dist,
    n_iter=5,  # try only 5 random combinations
    scoring='neg_mean_squared_error',
    cv=2,
    n_jobs=-1,
    random_state=42
)

rs.fit(x_train_small, y_train_small)
best_model = rs.best_estimator_
print("Best CV AUC:", rs.best_score_)
print(rs.best_params_) #{'n_estimators': 10, 'min_samples_leaf': 2, 'max_depth': 8}

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor
x_train_small = x_train_sample.sample(n=20000, random_state=42)
y_train_small = y_train_sample.loc[x_train_small.index]
param_grid = {
    'n_estimators': [10, 20],
    'max_depth': [6, 8, 10],
    'min_samples_leaf': [1, 2, 4],
}

g = GridSearchCV(
    estimator=RandomForestRegressor(),
    param_grid=param_grid,
    scoring='neg_mean_squared_error', #smaller and more close to zero->better model
    cv=2,
    n_jobs=-1

)

g.fit(x_train_sample, y_train_sample)
best_model = g.best_estimator_
print(g.best_params_)#{'max_depth': 10, 'min_samples_leaf': 1, 'n_estimators': 20}
print(g.best_score_) #-0.0011332923599805017
#took close to 2 minute for execution

from sklearn.model_selection import learning_curve
from matplotlib import pyplot as plt
train_sizes, train_scores, val_scores = learning_curve(
    best_model,
    x_train_small,
    y_train_small,
    cv=2,
    scoring='neg_mean_squared_error',
    train_sizes=np.linspace(0.1, 1.0, 5),
    n_jobs=-1
)

plt.figure(figsize=(6,5))
plt.plot(train_sizes, train_scores.mean(axis=1), label='Train AUC')
plt.plot(train_sizes, val_scores.mean(axis=1), label='Validation AUC')
plt.xlabel("Training Size")
plt.ylabel("AUC")
plt.title("Learning Curve – Power consumption")
plt.legend()
plt.show()

